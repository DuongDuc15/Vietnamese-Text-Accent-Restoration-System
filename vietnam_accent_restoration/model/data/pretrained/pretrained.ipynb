{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pretrained.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1cNGFfHL9kb4uU73L0iMJwdpG2pFP_ecR","authorship_tag":"ABX9TyNxAYDU8fSWmiWx4ak+BOmq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":642},"id":"uTX__SRDAUvl","executionInfo":{"status":"error","timestamp":1635192393176,"user_tz":-420,"elapsed":3465,"user":{"displayName":"Duong Minh Duc (K15 HL)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17816393020370832646"}},"outputId":"3388663a-7641-4bf5-8f87-14cf560cd173"},"source":["import tensorflow_datasets as tfds\n","import tensorflow as tf\n","\n","import time\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Load tokenizer\n","import pickle\n","\n","def _save_pickle(path, obj):\n","  with open(path, 'wb') as f:\n","    pickle.dump(obj, f)\n","\n","def _load_pickle(path):\n","  with open(path, 'rb') as f:\n","    obj = pickle.load(f)\n","  return obj\n","\n","tokenizer_ipt = _load_pickle('/content/drive/MyDrive/Colab Notebooks/AIP/pretrained/tokenizer/tokenizer_ipt.pkl')\n","tokenizer_opt = _load_pickle('/content/drive/MyDrive/Colab Notebooks/AIP/pretrained/tokenizer/tokenizer_opt.pkl')\n","\n","# Khai báo tham số\n","num_layers = 4\n","d_model = 128\n","dff = 512\n","num_heads = 8\n","\n","input_vocab_size = tokenizer_ipt.vocab_size + 2\n","target_vocab_size = tokenizer_opt.vocab_size + 2\n","dropout_rate = 0.1\n","learning_rate = 0.01"],"execution_count":3,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-b4d27ca644e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mtokenizer_ipt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Colab Notebooks/AIP/pretrained/tokenizer/tokenizer_ipt.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mtokenizer_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Colab Notebooks/AIP/pretrained/tokenizer/tokenizer_opt.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-b4d27ca644e0>\u001b[0m in \u001b[0;36m_load_pickle\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_load_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_datasets.core.features.text'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","metadata":{"id":"vUrCqgcCDiBo"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YtzYs4UkDxYy"},"source":[""],"execution_count":null,"outputs":[]}]}